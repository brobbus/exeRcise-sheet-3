---
title: "Exercise #3"
subtitle: "Fortgeschrittene Statistische Software für NF"
author: "Brendan Kearney (12584004), Eva Thoma (12546840), Dilara Tuncyürek (12629737)"
date: "`r Sys.Date()`"
output: distill::distill_article
---

## General Remarks

-   You can submit your solutions in teams of up to 3 students.
-   Include all your team-member's names and student numbers
    (Martrikelnummern) in the `authors` field.
-   Please use the exercise template document to work on and submit your
    results.
-   Use a level 2 heading for each new exercise and answer each subtask
    next to it's bullet point or use a new level 3 heading if you want.
-   Always render the R code for your solutions and make sure to include
    the resulting data in your rendered document.
    -   Make sure to not print more than 10 rows of data (unless
        specifically instructed to).
-   Always submit both the rendered document(s) as well as your source
    Rmarkdown document. Submit the files separately on moodle, **not**
    as a zip archive.

## Exercise 1: Initializing git (4 Points)

For this whole exercise sheet we will be tracking all our changes to it
in git.

### a)  Start by initializing a new R project with git support, called
    `2024-exeRcise-sheet-3`. If you forgot how to do this, you can
    follow this
    [guide](https://malikaihle.github.io/Introduction-RStudio-Git-GitHub/rstudio_project.html).
### b)  Commit the files generated by Rstudio.
### c)  For all of the following tasks in this exercise sheet we ask you to
    always commit your changes after finishing each subtask e.g. create
    a commit after task *1d*, *1e* etc.

> Note: This applies only to answers that have text or code as their
> answer. If you complete tasks in a different order or forget to commit
> one, this is no problem. If you change your answers you can just
> create multiple commits to track the changes. 
 
Ich Commite alle Aufgaben am Ende in richtiger Reihenfolge
### d)  Name 2 strengths and 2 weaknesses of git. (Don't forget to create a
    commit after this answer, see *1c*)
    
Advantages:
1. Increases flexibility and reliability since you can work offline and only share your changes when you're ready. 
2. Changes can be easily integrated.

Disadvantages: 
1. Managing large files can slow down operations and increase storage requirements. 
2. Learning and mastering Git commands can be a barrier to entry for some developers.
    
### e)  Knit this exercise sheet. Some new files will automatically be
    generated when knitting the sheet e.g. the HTML page. Ignore these
    files, as we only want to track the source files themselves.

## Exercise 2: Putting your Repository on GitHub (3.5 Points)

For this task you will upload your solution to GitHub.

### a)  Create a new repository on GitHub in your account named
    `exeRcise-sheet-3`. Make sure you create a **public repository** so
    we are able to see it for grading. Add the link to the repository
    below: https://github.com/brobbus/exeRcise-sheet-3
### b)  Push your code to this new repository by copying and executing the
    snippet on github listed under
    `…or push an existing repository from the command line`.
### c)  Regularly push your latest changes to GitHub again and especially do
    so when you are finished with this sheet.

## Exercise 3: Baby-Names in Munich (3.5 Points)

Download the latest open datasets on given names ("Vornamen") from the
open data repository of the city of Munich for the years `2023` and
`2022`.

Link: <https://opendata.muenchen.de/dataset/vornamen-von-neugeborenen>

### a)  Download the data for both years and track it in git. For small
    datasets like these adding them to git is not a problem.

### b)  Load the data for both years into R. Check the type of the count
    variable ("Anzahl") and look into the data to determine why it is
    not numeric? Fix the problem in an appropriate manner, it is OK if
    some of the counts are inaccurate because of this. Explain your
    solution and the repercussions.
```{r}
library(tidyverse)
data_2022 <- read_csv("data/open_data_portal_2022.csv")

data_2023 <- read_csv("data/vornamen-muenchen-2023.csv")

typeof(data_2022$Anzahl)
typeof(data_2023$Anzahl)

data_2022 <- data_2022 %>%
  mutate(Anzahl = parse_number(Anzahl))
data_2023 <- data_2023 %>%
  mutate(Anzahl = parse_number(Anzahl))
#parse_number removes all non-numeric content and converts the contents of columm "Anzahl" into numeric values. However, the information "4 or less" is lost. 
```

### c)  Calculate the total number of babies born in Munich in 2022
    and 2023. Which year had the bigger baby-boom?
```{r}
sum(data_2022$Anzahl, na.rm = TRUE)
sum(data_2023$Anzahl, na.rm = TRUE)
```
2022 had the bigger baby-boom.

### d)  Add a new column `year` to both datasets which holds the correct
    year for each.
```{r}
data_2022$year <- 2022
data_2023$year <- 2023
```

### e)  Combine both datasets into one using `bind_rows()`.
```{r}
combined_data <- bind_rows(data_2022, data_2023)
```

### f)  Combine the counts for same names to determine the most popular
    names across both years. Print out the top 10 names in a nicely
    formatted table for both years. Include a table caption.
```{r}
top_10_names_2022 <- head(combined_data, n = 10) %>%
  mutate(year = 2022) %>%
  select(year, Vorname, Anzahl)

top_10_names_2023 <- head(combined_data, n = 10) %>%
  mutate(Year = 2023) %>%
  select(Year, Vorname, Anzahl)

install.packages("kableExtra")
library(kableExtra)

table_2022 <- top_10_names_2022 %>%
  kbl(caption = "Top 10 Namen für das Jahr 2022") %>%
  kable_classic()
table_2022

table_2023 <- top_10_names_2023 %>%
  kbl(caption = "Top 10 Namen für das Jahr 2023") %>%
  kable_classic()
table_2023
```

## Exercise 4: Open Analysis (4 points)

This exercise is a bit more open-ended. You can choose any dataset from
[Our World in Data](https://ourworldindata.org/) and analyze it, while
determining the research question yourself.

### a)  Go to <https://github.com/owid/owid-datasets/tree/master/datasets>
    and choose a dataset that interests you. You can have a look at
    <https://ourworldindata.org/> to gather some inspiration.
### b)  Download the dataset and track it in git.
### c)  Put the name / title of the dataset and a link to it below.

-   Dataset Name: Adding Adult obesity by region - FAO (2017)
-   Link: https://github.com/owid/owid-datasets/blob/master/datasets/Adult%20obesity%20by%20region%20-%20FAO%20(2017)/Adult%20obesity%20by%20region%20-%20FAO%20(2017).csv
### d)  Come up with a (research) question you want to answer with the data
    and briefly explain why you believe this is an interesting question
    within one sentence. It should be a question that can be answered
    with the dataset and using R.
```{r}
fat_people <- read.csv("data/Adult obesity by region - FAO (2017).csv")
```
 Research Question:
How much did the number of overweight adults change around the world and in different continents between 1975 and 2014?

Brief Explanation:
We want to see how many adults became overweight over the years, and if it was different depending on where they lived. This helps us understand how the problem of being overweight has changed and what areas need more help.
   
### e)  Use R to answer your chosen question.
```{r}
library(dplyr)
library(tidyr)

# Step 1: Calculate prevalence of obesity in earliest and latest years for each region 
earliest_year <- min(fat_people$Year)
latest_year <- max(fat_people$Year)

obesity_prevalence <- fat_people %>%
  filter(Year %in% c(earliest_year, latest_year)) %>%
  pivot_wider(names_from = Year, values_from = Prevalence.of.obesity.in.adults..18..years.old...FAO..2017..) %>%
  rename(obesity_earliest = `1975`, obesity_latest = `2014`) %>%
  mutate(change_in_obesity = obesity_latest - obesity_earliest)

# Step 2: Calculate the difference in obesity rates between the earliest and latest years for each region 
change_in_obesity <- obesity_prevalence %>%
  select(Entity, change_in_obesity) %>%
  arrange(desc(change_in_obesity))

# Step 3: Visualize the change in obesity rates over time and across regions 
ggplot(change_in_obesity, aes(x = reorder(Entity, change_in_obesity), y = change_in_obesity)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(x = "Region", y = "Change in Obesity Rate (%)",
       title = "Change in Obesity Rate Between Earliest and Latest Years by Region") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

continent_avg <- fat_people %>%
  group_by(Entity) %>%
  summarize(avg_obesity = mean(Prevalence.of.obesity.in.adults..18..years.old...FAO..2017.., na.rm = TRUE)) %>%
  arrange(desc(avg_obesity))

```
North America and Europe are on average the continents with the most obese people. However, the growth in Oceania has been the biggest. On average obesity worldwide has been about 8.3% higher in 2014 than it was in 1975. 

### f)  Create a meaningful plot / figure with the dataset. Make sure to
    provide a figure caption (via the chunk options / Rmarkdown) and
    correctly label the figure.
```{r}
#simple code
install.packages("tidyverse")
library(tidyverse)
ggplot(fat_people, aes(x = Year, y = Prevalence.of.obesity.in.adults..18..years.old...FAO..2017.., color = Entity)) +
  geom_line() +
  labs(x = "Year", y = "Prevalence of obesity (%)", title = "Obesity Prevalence Over Time by Continent") +
  theme_minimal()

install.packages("gganimate")
install.packages("gifski")
install.packages("transformr")

library(dplyr)
library(readr)
library(ggplot2)
library(gganimate)
#animation
anime <- ggplot(fat_people, 
               aes(
                 x = Year, 
                 y = Prevalence.of.obesity.in.adults..18..years.old...FAO..2017.., 
                 color = Entity)) +
  geom_point(alpha = 0.6) +
  scale_x_log10() +
  theme_bw(base_size = 8) +
  labs(title = "Trends in Adult Obesity Rates by Region (1975-2014)",
       x = "Year",
       y = "Prevalence of obesity",
       color = "Entity") +
  theme_minimal() +
  transition_time(Year)

anime
```


## Final Note

Make sure to push all your commits and changes to GitHub before
submittining the exercise sheet.
